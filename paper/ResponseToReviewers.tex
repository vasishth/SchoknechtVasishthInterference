\documentclass[12pt]{article}
\usepackage[a4paper,top=2cm,bottom=2cm,left=2.5cm,right=2.5cm,marginparwidth=1.75cm]{geometry}
%\geometry{landscape}                % Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{float}
\usepackage{subfigure}
\usepackage{rotating}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{color}
\usepackage{gb4e}
\noautomath

%\usepackage[backend=biber,useprefix=true,style=apa,url=false,sorting=nyt,eprint=false]{biblatex}

%\addbibresource{interferencebib.bib}

\usepackage[natbib=true,maxcitenames=2,bibstyle=authoryear, style=apa]{biblatex}
\usepackage{csquotes}
\DeclareLanguageMapping{american}{american-apa}
\bibliography{interferencebib}

\usepackage{marginnote}
\setcounter{section}{-1}

\usepackage{lineno,xcolor,clipboard,graphicx}

\openclipboard{output-reviews}

\renewcommand{\qedsymbol}{\rule{0.7em}{0.7em}}

\usepackage{epstopdf}
\newcommand{\revised}[1]{{\color{black}{#1}}}

\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\title{Response to editor and reviewers (JML-24-17)}
\author{Pia Schoknecht and Shravan Vasishth}
%\date{}                                           % Activate to display a given date or no date


\usepackage{xr}

\makeatletter
\newcommand*{\addFileDependency}[1]{% argument=file name and extension
\typeout{(#1)}% latexmk will find this if $recorder=0
% however, in that case, it will ignore #1 if it is a .aux or 
% .pdf file etc and it exists! If it doesn't exist, it will appear 
% in the list of dependents regardless)
%
% Write the following if you want it to appear in \listfiles 
% --- although not really necessary and latexmk doesn't use this
%
\@addtofilelist{#1}
%
% latexmk will find this message if #1 doesn't exist (yet)
\IfFileExists{#1}{}{\typeout{No file #1.}}
}\makeatother

\newcommand*{\myexternaldocument}[1]{%
\externaldocument{#1}%
\addFileDependency{#1.tex}%
\addFileDependency{#1.aux}%
}

\myexternaldocument{main}

\begin{document}
\hfill \today
%\section{}
%\subsection{}

\noindent \textbf{Prof. Chris Jarrold}\\
\noindent \textbf{Associate Editor}\\
\noindent \textbf{Journal of Memory and Language}
\vskip 1em

\noindent \textbf{Response letter for Submission JML-24-17}
\vskip 2em
\noindent Dear Prof. Jarrold, 
\vskip 1em
Together with my co-author Shravan Vasishth, I would like to submit our
revision of the article titled ``Do syntactic and semantic similarity lead to interference effects? Evidence from self-paced reading and event-related potentials using German''.
We are grateful for thoughtful and constructive comments and suggestions from you and the reviewers, and feel that the quality of the manuscript has been greatly improved by the revisions.

You noted in your decision letter that the manuscript could potentially be a valuable contribution to the special issue, a view largely shared by the reviewers. 

Reviewer 1 was concerned with some decisions that we had made in our computational modeling and statistical analyses and the interpretation of the results. In response to the concerns about our statistical analyses, we have completely re-done the analyses of the reading times and ERP data and added analyses of the previous data. Additionally, we have added one computational model and use k-fold cross-validation for model comparisons. We believe that these new analyses strengthen our initial interpretation that our study shows semantic interference, but no syntactic interference and no interaction. 

Reviewer 2 primarily raised concerns regarding our experimental design. In response to the concerns about our experimental design, we have emphasized that we used a well-established design that was previously published in, among other journals, the \textit{Journal of Memory and Language}. We now stress in the paper that we are building on previously published work by directly comparing the statistical inferences, using Bayes factors, from the present and previous studies that use exactly the same design. 

Reviewer 3 suggested a more in-depth discussion of the mechanisms of cue-based retrieval and had some concerns about our methodology. We have added a more detailed discussion of the memory mechanisms which are assumed to underlie sentence processing in the present design. We have added a thorough discussion of all concerns which were raised regarding our methodology. 

Below, we separately address each comment from the reviewers. All changes have been highlighted in the revised manuscript. The actionable parts of the comments from the reviewers and yourself are highlighted in bold.

\vskip 1em
\noindent Sincerely,
\vskip 1em
\noindent Pia Schoknecht\\
Postdoctoral researcher\\
Department of Linguistics\\
University of Potsdam, Germany
\thispagestyle{empty}
\newpage

\section*{Editor's comments} 
\subsection*{Comment E.1}
\begin{quote}
``Dear Dr. Schoknecht,

Thank you for submitting your manuscript to our special issue on the Language-Memory Interface at the Journal of Memory and Language. Your paper has now been reviewed by three experts in the field and your will find their comments below. I also read the manuscript carefully myself before turning to the reviews.

You will see that all three of the reviews are thorough, well-informed, and detailed and I am grateful to the reviewers for the care and time they have clearly put in to reading the manuscript. My own reading aligned with Reviewer 1's assessment in that I found your paper to be very clearly written and enjoyable to read. Your very good sample sizes and sophisticated analyses and modelling suggest to me that this work has the potential to make a strong contribution to our special issue.

However, I am far from being an expert in this area, and the (therefore much more knowledgeable) reviewers have raised a number of issues with the paper, some of which I judge to be substantive. For this reason I have come to a 'revise and resubmit' decision. If you do revise and resubmit your paper, as I hope you will, I will approach the same set of reviewers to see if they are able to re-review (and obviously there is no guarantee of acceptance at that stage).

In revising your paper you should take into account all of the reviewer's points. However, there are two themes that I picked out as particularly important.

First, \textbf{Reviewer 2 raises a potentially serious concern that your particular manipulation of syntactic dis/similarity might not be expected to lead to substantial syntactic interference (their point 1)}. In other words, the questions are whether one would ever expect to see much of this effect with your design and whether a more appropriate design would lead to stronger findings. Some of Reviewer 3's points (see their paragraph starting 'The authors attribute ...' and their final summary comment) are perhaps in the same vein.''
\end{quote}

\subsection*{Response to E.1}
We have used a well-studied design that was previously published in the Journal of Memory and Language, among other places. The previously publisheed studies use exactly the same design, specifically the same syntactic retrieval cue, and found effects of syntactic interference \citep{vandyke07,mertzen}.
It is possible that the reviewer is right to not expect the design to lead to decisive syntactic interference effects because the syntactic manipulation might not be appropriate. However, we are building the previously published claim that this design leads to syntactic interference. We believe that our results are a valuable contribution to the literature on syntactic interference, and serves as an important counterpoint to the previously published claims \citep{vandyke07, mertzen}. The reviewer's objection can and should be pursued in a future study that uses a design that the reviewer would consider appropriate, but this would require a completely new paper with a different research focus (namely, what is an appropriate syntactic manipulation that would lead to interference?). We now mention in the General Discussion
that such a future investigation is needed.

We added the following text to our General Discussion on page \pageref{only_this_design} to emphasize that our findings and conclusions only apply to the present design:

\Paste{only_this_design}

\subsection*{Comment E.2}

\begin{quote}
``Second, a couple of Reviewer 1's comments (e.g., their point 2, and their final point about priors) relate to the fact that \textbf{there actually is some evidence for a degree of syntactic interference in aspects of the data, particularly perhaps in terms of the interaction and the combination with high semantic similarity, that you risk underplaying} (see also Reviewer 2's point 5).''
\end{quote}


\subsection*{Response to E.2}
We have re-done our analyses in response to the concerns raised by the reviewers and the Bayes factors from the revised analyses still do not provide evidence for syntactic interference or the interaction.

As an overview of the revised Bayes factor analyses, we show below the Figures \ref{fig:spr_bfs} and \ref{fig:eeg_bfs}.

\setcounter{figure}{4}
\Paste{fig_bf_spr}

\setcounter{figure}{10}
\Paste{fig_bf_eeg}

\subsection*{Comment E.3}
\begin{quote}
``Finally, I would also add that while I agree with Reviewer 1's assessment that your paper would fit well in the special issue, \textbf{as someone more versed in the memory than the language literature I thought you could be more explicit about how your findings do integrate both of these two areas.}''
\end{quote}

\subsection*{Response to E.3}
\textcolor{red}{??}

\subsection*{Comment E.4}
\begin{quote}
``The reviewers have made suggestions which the Editors feel will improve your manuscript. We encourage you to consider these comments and make an appropriate revision of your manuscript.

We are trying to improve the reproducibility of work published in the Journal. \textbf{Please ensure that you have included a ``Data Availability" statement immediately before your empirical work with a link to materials, data, and analysis code}(see our `guide for authors' for instructions). Please make sure that you have updated the data and analysis code following any revisions to your manuscript. Please confirm in your next covering letter that all results presented in your manuscript can be reproduced using the materials that you have made available.''
\end{quote}


\subsection*{Response to E.4}
We have moved our data availability statement to page \pageref{statement}, before Experiments 1a and 1b:

\Paste{osf}

\section*{Reviewer \#1's comments} 
\subsection*{Comment R1.1}
\begin{quote}
``In the manuscript "Do syntactic and semantic similarity lead to interference effects? Evidence from self-paced reading and event-related potentials using German" the authors investigate the effect of syntactic and semantic interference in a large-sample self-paced reading and EEG studies that follow in design Van Dyke (2007) and Mertzen et al. (2023).

This is a very interesting paper with solid findings, well-written and relevant for the JML special issue on language and memory. I really enjoyed reading it - I very much liked the rigorous combination of experimental work with a Bayesian analysis and computational cognitive modeling. The data, while largely replicating previous studies, are important for a discussion on memory and language and would deserve to be available to scientific community. All in all, I can see a path forward to publication for the manuscript. At the same time, though, I do have several issues that in my opinion should be resolved - mainly regarding the interpretation of the results and several modeling choices. I discuss these issues, listed by topic, below.

Interpretation of the results\\
================

One of the main findings is that the studies show a convincing, strong effect of semantic interference, but the effect of syntactic interference (of syntax-semantics interaction) is not present. This is in contrast to several previous studies, which did show syntactic interference, in addition to semantic interference.

In Discussion, the authors propose the interpretation of the results in a cue-based retrieval model, in which two cues are relevant for retrieval: [+subject in-same-clause], [+animate].

I have several problems with this interpretation:

1. Encoding vs.\ retrieval: As far as I can see, \textbf{the interpretation cast in the Lewis and Vasishth (2005) model means that the interference is present at retrieval, not at encoding. But that goes against the proposed informal interpretation of the findings of the self-paced reading study. There it is argued that the observed effect of semantic interference is due to *encoding*, not (just) retrieval. That is, there is a discrepancy between the informal interpretation of the self-paced reading study and the computational model.} ''\end{quote}

\subsubsection*{Response to R1.1}
The reviewer is right. The Lewis and Vasishth (2005) model is a model of memory retrieval during sentence processing and should therefore not be used to model effects of encoding interference. We have removed the modeling of the SPR effects. In the revised manuscript, we now only present modeling of retrieval interference in ERPs. 

\subsection*{Comment R1.2}
\begin{quote}
``2. Match of the model and data: The interpretation is set in such a way that only semantic interference, but no syntactic interference or interaction are predicted. This is achieved by hard-coding that the syntactic cue selects the target and nothing else. I find this problematic. For the modeling results of the current experiment, in Figure 11 it seems that the syntactic interference and interaction are underpredicted by the model - not by much, but they are. While the model predicts no effect, the data do show an effect, be it small (btw, it is hard to read this figure because of the chosen scale; \textbf{it would be much better to zoom in and show for example 0-30 ms scale for the reading study 0 to -1 microvolt scale for the EEG study)}.''\end{quote}

\subsubsection*{Response to R1.2}
We have re-done the Figure to reflect our revised modeling. We hope that the scale of the new Figure is easier to read:

\Paste{figpriorposteriordata}


\subsection*{Comment R1.3}
\begin{quote}
``In my reading, the discrepancy mainly comes from the fact that the decision to neglect syntactic interference is based on Bayes factors (see also below), but when matching the model predictions to actual results (p. 39-42), the match is done on posterior distributions, which do show a positive effect of interaction (the self-paced reading study) and an effect of syntactic interference (the self-paced reading study and the EEG study). \textbf{I think what the authors could do to at least partially address this issue is to be more explicit about model comparisons. They could leverage their use of Bayes factors to compare different computational models - the one proposed in this paper, which hard-codes that only the syntactic target is selected, the one based on Mertzen et al., possibly with varying priors, and, possibly, a null model which does not predict any interference (e.g., it hard-codes that only the target is retrieved).}''\end{quote}

\subsubsection*{Response to R1.3}
\textcolor{red}{Do k-fold crossvalidation of computational models of ERP data}

\subsection*{Comment R1.4}
\begin{quote}
``3. Comparison to previous findings: Syntactic interference has been observed previously. The authors discuss in detail Van Dyke (2007) and Mertzen et al. (2023) as two studies that argue for syntactic interference. This is in contrast to the current study, which is claimed not to show syntactic interference. One problem for me is that we are not making a fair comparison: the current study bases its interpretation on Bayes factors, which were not used in Van Dyke or Mertzen et al. To be sure, my point is not that Bayes factors should not be used (of course, I find it good that they are used to compare hypotheses), just that the comparison between this study and the other findings is far from straightforward. If we only check posterior distributions, which were explored in Mertzen et al. for their conclusions, we do see some effect of syntactic interference - e.g., the predominantly negative credible interval in the EEG study. As far as I can see, \textbf{to really make a sensible comparison, one would either have to reanalyze Mertzen and Van Dyke's data using Bayes factors or be more precise in explaining how the posterior distributions in this study differ from previous studies} - just looking at the posteriors, they do not seem to paint such different pictures between the current study and Mertzen et al. ''\end{quote}

\subsubsection*{Response to R1.4}
In the revised manuscript, we are now more explicit about the comparison to previous findings. We have added a new figure (Figure \ref{fig:previous_vs_present}) to the General Discussion. The new figure shows the estimates of the previous studies and Bayes factors which we have computed for the previous studies, along with our own estimates and Bayes factors. The following was added to the manuscript:
\setcounter{figure}{11}

\Paste{comparison}


\subsection*{Comment R1.5}
\begin{quote}
``Another problem I have is more general and has to do with progress in science. The authors in my reading find the current findings more convincing than, say, Mertzen et al. study. I get that the current study is convincing (I do find it convincing) but that does not disqualify what Mertzen et al. found in any way - both results co-exist. Ideally, I would expect that a model would be able to explain the current data, but also the past data. I get it that this is not always possible but then, \textbf{it would be good if the authors make their position explicit - either by admitting that only some data can be captured, or, if the authors believe that the past data should be ignored, it should be explained why this is so.}

All in all, I think the interpretation of the data and the model have to be strengthened to meet requirements 1-3. Alternatively, the manuscript should explicitly admit issues in the proposed interpretation - that is, explain that the model fails to capture encoding interference (point 1 if I am right), explain why the model underpredicts interference in syntax/interaction and explain why it is enough, at least for now, to only model the current findings and to put previous findings aside (assuming they actually differ - see point 3 about Bayes factors above).''\end{quote}

\subsubsection*{Response to R1.5}
\textcolor{red}{Write something about the co-existence of contradictory results}

\subsection*{Comment R1.6}
\begin{quote}
``Semantic encoding interference vs.\ acceptability\\
===========================

It is proposed that the semantic interference in the self-paced reading study is due to encoding. This interpretation is supported by the fact that we observe increased reading times from the moment that the +animate distractor is read (nicely shown in Figure 3). I wonder whether an even more straightforward interpretation is possible here. Could the effect of increased reading times simply be due to the fact that the +animate distractor is not as good as the -animate distractor in this context? That is, the effect has nothing to do with encoding interference, it's just a consequence of the fact that, e.g., in (2a) the statement that "the burglar was awful" is harder to make sense of than that "the loss was awful". \textbf{I think one easy way to check it would be to run an acceptability/plausibility study which checks whether the +animate version and the -animate version are comparable in their acceptability.} I know that the manuscript mentions a possible confound due to plausibility (p. 22, 23) but as far as I could understand it is assumed that this confound would only affect the syntactic manipulation, not the semantic one. However, I think the semantic manipulation could just as well result in more or less plausible sentences.''\end{quote}

\subsubsection*{Response to R1.6}
We ran the suggested plausibility judgement experiment. The -animate distractor is indeed slightly more plausible in the context than the +animate distractor. We discuss this potential confound in the revised manuscript starting on page \pageref{plausib_anim_inan}:

\Paste{plausib_anim_inan}


\subsection*{Comment R1.7}
\begin{quote}
``Intercept-only models\\
=============

Models with intercept-only random-effect structures are used for the data analysis. I see why this has to be done for Bayes factors. I wonder, though, whether this justifies the use of intercept-only models to find posterior distributions of parameters. I would worry that given that all Bayes models have intercept-only random-effect structures, we probably overestimate the size of fixed effects (e.g., in Figure 4). \textbf{Why not doing the following: one could use models with full random effect structure for estimation of posterior distribution of parameters, and then switch to intercept-only models to calculate Bayes factors,} since more complex models lead to unstable Bayes factors.''\end{quote}


\subsubsection*{Response to R1.7}
As mentioned in our response to R1.4, we recomputed our Bayes Factors using the Savage-Dickey method. With this method, we were able to compute Bayes Factors for models with complex random effect structures. We have re-run all models with full random effect structures and updated all results in the manuscript accordingly.

\subsection*{Comment R1.8}
\begin{quote}
``Priors for Bayes factors\\
=============

Various priors are considered for Bayes factors. \textbf{Of course, it is good to explore several values but I wonder whether it is justified to conclude that syntactic interference or interaction should be excluded if they are not supported in models with unreasonably large priors (e.g., N+(0, 0.1)). Would anybody expect that interference is in range of 0.1 log-ms? As one of the authors of this manuscript nicely showed in Jager et al. (2017) and Schad et al. (2022), interference effects are small (at least for subject-verb agreement and ungrammatical illusions). Given that, I don't understand why we require a BF in favor of interference for a prior that is of size N+(0, 0.1). Shouldn't a smaller prior distribution suffice as evidence? This brings me again to my confusion in what the experiments actually show. The authors seem to argue that the only interference is the semantic one and they base the conclusion on large priors. But focusing on small priors (N+(0, 0.05) for spr, N-(0, 0.5) for EEG)), one could conclude that the interaction/syntactic interference might be present after all. Is there an independent reason to select the former priors over the latter for one's interpretation? To be sure, I don't want the authors to change the interpretation, but I would like to see either a more explicit argumentation why we should base our conclusion on such and such priors, or a more reflection in the text that explicitly states that the results are not equivocal and the current study is still compatible with a position that syntactic interference and/or interaction are real.}''\end{quote}

\subsubsection*{Response to R1.8}
BFs do not to need to be strongly in favor of an effect across all investigated priors to conclude that an effect is supported. However, to draw decisive conclusions in favor of an effect, the evidence for that effect should be stronger than anecdotal for at least a subset of reasonable priors.

The meta-analysis of reading time studies by \textcite{jaeger_etal_2017} showed that the pooled estimate of inhibitory interference across studies with similar designs as ours was indeed small (13.1 ms, page 327), but some studies showed effects around 50 ms (e.g., two of the sub-experiments from \cite{vandyke07}) and one experiment by Franck et al., (2015) even showed an estimate above 100 ms (see Figure 2 on page 329 of \cite{jaeger_etal_2017}). Because such large interference effects have been found previously (see also our new Figure 12 showing all estimates of \cite{vandyke07} and \cite{mertzen}), we believe that it is reasonable to explore a wide range of a priori effect sizes, specifically from $\pm$8 to $\pm$80 ms for the reading times. 

We have revised the description of the SPR results to include more nuance regarding the BFs under the different priors:

\setcounter{figure}{4}
\Paste{SPR_bfs}

For the analysis of the ERP data, we changed the largest prior from N(0,5) to N(0,2), so from effects ranging up to 11 $\mu V$ to effects ranging up to 4 $\mu V$, to accommodate the concern that we might focus on too large effect sizes. We have revised the description of the BF analysis for the ERP data as follows (see page \pageref{ERP_results3}):

\Paste{ERP_results3}


\section*{Reviewer \#2} 
\subsection*{Comment R2.1}
\begin{quote}
``This paper reports two high-powered studies (SPR and ERP) in German aiming to investigate the role of both syntactic and semantic interference in sentence comprehension. The authors investigate syntactic interference by manipulating the syntactic status of the distractor (subject vs. non-subject), and semantic interference by manipulating the semantic status of the distractor (animate vs. inanimate). Results show evidence for semantic interference and evidence against syntactic interference. With the aim to reconcile their results with the vast literature attesting to a clear role of syntactic interference, the authors suggest that the parser is driven by structural information allowing it to discard syntactically implausible elements as potential retrieval targets, thereby mitigating their potential for intervention.

While I am favorably impressed by the large-sample size tested by the authors and the meticulous statistical analyses, I also have concerns regarding the paper's overall lack of theoretical depth, the operationalization of syntactic interference, as well as several decisions made by the authors in generating materials.

I honestly don't know if these problems can be resolved in a major revision, or whether they will require so much new experimentation and/or theorizing that the manuscript which results would be essentially a new manuscript. I'll leave that to the editor.

I discuss my concerns in turn.

The authors identify 2 major problems with the previous literature I agree with: 1) studies lacking sufficient statistical power, and 2) ambiguity regarding which cues are pertinent for retrieval.

They address the 1st concern by increasing the number of participants and items tested, which is commendable. Regarding the second issue, they address it by testing both syntactic and semantic cues. As a syntactic cue, the authors tested "being a subject". In the high syntactic interference condition, the distractor functions as the subject of an embedded clause that serves as the complement of a non-restrictive relative clause (who had told her that the loss/ burglar was awful). In the low syntactic interference condition, the distractor is within a prepositional phrase serving as the complement of a non-restrictive relative clause (who had told her about the awful loss/ burglar).

1. From a theoretical point of view, "being a subject" is not a primitive. Subjects are identified by a cluster of features. One of these features is c-command (the subject c-commands the verb). There is a whole literature (in agreement attraction, for instance) showing that distractors that c-command the verb generate strong syntactic interference even when they do not linearly intervene between the subject and the verb (and even when they are not subject themselves). So, we know, as a matter of fact, that syntactic interference is real.
The authors are concerned about underpowered studies, a concern I totally agree with. But it's a real shame they used the full force of Bayesian analysis, EEG, and a very good-sized subject pool to test conditions that do not instantiate the basic ingredients I would expect to generate syntactic interference, leading the authors to reinvent the wheel: the parser is not considering an element that could never serve as the potential subject of the matrix clause during subject retrieval.

Unsurprisingly, the authors reach this very same conclusion: "We speculate that one possibility might be that the parser tracks hierarchical structure and that this hierarchical information is used when searching for a noun in memory." Yes, exactly, but this isn't new.

I also agree with this statement (p.41): "[…] the parser intelligently targets only the syntactically relevant noun during antecedent retrieval. In the present case, it is possible that syntactically relevant noun is only the one in the same clause as the verb." Once again, yes, that's accurate. However, \textbf{this implies that the syntactic manipulation the authors went for is just not doing the job the authors would like it to do: the syntactic distractor is not a syntactically relevant noun. Being a subject of whichever clause at whichever level of embedding is not a sensible manipulation to test syntactic interference.}

2. The syntactic manipulation does not lead to minimally different conditions (i.e., conditions that only differ on the critical manipulation). These are the glosses for the two syntactic conditions:\\

who told had that the burglar/loss awful was\\
who about the awful burglar/loss told had\\

These are completely different structures with even different word orders. As a result, any difference in RTs observed at the critical region might ensue from a number of different reasons that might have nothing to do with burglar/loss being or not the subject of the embedded clause.

3. The semantic manipulation is not minimal either. In this case, not only is the number of letters different (as acknowledged by the authors themselves), but even the number of syllables isn't the same. Once more, this is not a minimal comparison.''
\end{quote}

\subsubsection*{Response to R2.1}
We believe that we have addressed this concern in our Response to E.1.

\subsection*{Comment R2.2}
\begin{quote}
``4. The difference in RTs starts at the distractor and continues through the critical verb region (in the high syntactic interference condition at least). Therefore, we cannot exclude the possibility that the effect observed at the critical verb is the same effect that originates at the distractor that is lingering through the sentence, rather than being a different effect altogether. Consequently, \textbf{I don't think that the effect at the critical region can be interpreted.}''
\end{quote}

\subsubsection*{Response to R2.2}
We agree with this statement and therefore refrained from interpreting the results at the critical region. To emphasize this point, we added the following to the manuscript on page \pageref{only_precritical}:\\

\Paste{only_precritical}

\subsection*{Comment R2.3}
\begin{quote}
``\textbf{(Furthermore, what's happening in regions 8-9? There is an increase in RTs in these regions in the high syntactic interference condition and a decrease in the low syntactic interference condition, while the trend for the remaining regions is quite similar. It's almost as if participants were able to discern the two syntactic conditions as early as region 8).}''
\end{quote}

\subsubsection*{Response to R2.3}
The participants were able to discern the two syntactic conditions at region 8 because this is the region were the conditions started to differ. We have added the words of an example item as x-axis labels to Figure \ref{fig:whole_sentence} on page \pageref{fig:whole_sentence} to illustrate clearly. For convenience, we paste the Figure here:
\newpage
\Paste{figwhole_sentence}

\newpage


\subsection*{Comment R2.4}
\begin{quote}
``5. \textbf{Another puzzling aspect is why the effect of the semantic manipulation only manifests in the high syntactic interference condition. The authors fail to address this interaction altogether.} Instead, they repeatedly emphasize finding evidence for semantic interference and against syntactic interference, without discussing the interaction. Once more, I believe these results are difficult to interpret, but it is surprising to see such a limited discussion of the findings.''
\end{quote}

\subsubsection*{Response to R2.4}
We agree with the Reviewer that visual inspection of Figure \ref{fig:whole_sentence} suggests an interaction, but the Bayes factor analysis, i.e., hypothesis testing, provided no evidence for the interaction. See the following text in the manuscript on page \pageref{insig_interaction}:

\Paste{insig_interaction}

We are not discussing the small interaction in the critical region because we refrained from interpreting effects after the pre-critical region due to pre-critical effects (see Response to R2.2).

\subsection*{Comment R2.5}
\begin{quote}
``6. \textbf{The N400 is traditionally considered to be the hallmark of semantic effects. However, what is the linking hypothesis between syntactic interference and N400? The paper fails to address this crucial point.}''
\end{quote}

\subsubsection*{Response to R2.5}
The linking hypothesis is that memory retrieval might modulate the N400. Any type of retrieval interference, may it be due to syntactic or semantic retrieval cues, might affect memory retrieval and therefore the N400. We added the following text to the paragraph about the regions of interest on page \pageref{why_n400}:

\Paste{why_n400} 

\vspace{1em}
\noindent Following, the argumentation that interference, especially syntactic interference, might influence the P600, we have added analyses of the spatio-temporal P600 window. These new analyses provide evidence against an effect of syntactic interference on the P600 and moderate bordering weak evidence for an effect of semantic interference. We added the following text to the Results on page \pageref{ERP_results1}:

\Paste{ERP_results1}

\noindent We added the following text to the Results on page \pageref{ERP_results2}:

\Paste{ERP_results2}

\noindent We added the following text to the Results on page \pageref{ERP_results3}:

\Paste{ERP_results3}


\noindent We added the following text to the Discussion on page \pageref{ERP_discussion}:

\Paste{ERP_discussion}

\subsection*{Comment R2.6}
\begin{quote}
``7. \textbf{It is noteworthy that the general discussion does not mention or discuss the works showing that hierarchical intervention matters in agreement attraction and that pre-date all the studies mentioned in the several parentheticals. I have in mind Franck et al. 2002, 2006 and 2011, for instance. These works offer a treatment of attraction in terms of intervention and, as far as my knowledge goes, these are the first studies highlighting the crucial role of hierarchical interference effects. While authors mention other papers about agreement attraction, they seem to overlook these particular ones.}''
\end{quote}

We have added the suggested references to page \pageref{franck_refs}:

\Paste{franck_refs}

\section*{Reviewer \#3} 
\subsection*{Comment R3.1}
\begin{quote}
``This article describes two experiments that test whether comprehension of subject-verb relations in complex sentences (in German) is disrupted by the presence of irrelevant-but-tempting nearby noun phrases. The temptation is due either to semantic properties ("good fit to the verb") or syntactic properties ("looks like a subject"). The key finding from both experiments is that semantic temptation effects are clear, while syntactic temptation effects are largely absent. The authors interpret this contrast as evidence for specific types of features used in sentence encoding and retrieval operations that should prevent effects of syntactic interference, i.e., if encountering a verb induces retrieval of "subject of the same clause", then the subject of a different clause shouldn't interfere.

The design of the current studies repeats a design used in previous studies in German and other languages. The more novel aspects of the current studies are the use of the ERP measure, and the inclusion of a very large number of participants, allowing for more precise estimates of the syntactic and semantic interference effects. The quantitative analyses are characteristically thorough and careful.

I would support publication in JML. But I think that the paper would be stronger if there was fuller engagement with the range of possible reasons for the observed effects. This covers (i) mechanisms that could capture the lack of a syntactic interference effect, and (ii) reasons for differences between the current study and others where a syntactic interference effect was found.

The authors attribute the lack of a syntactic interference effect to the use of a syntactic feature like "subject of the same clause", which has the effect that a subject of a different clause does not count as similar to the retrieval cue. This gives a special status to the correct subject via the choice of retrieval cues. \textbf{There may be other ways of giving special status to the correct subject, and thereby capturing the lack of syntactic interference. For example, if the subject of the current clause is encoded in a special status, e.g., with boosted activation, or with its needs prioritized, then this could have a similar effect.}''
\end{quote}

\subsubsection*{Response to R3.1}
\textcolor{red}{??}

\subsection*{Comment R3.2}
\begin{quote}
``The use of a feature like "subject of the same clause" calls for some further discussion, since, taken literally, this is not a likely feature of a subject phrase in memory. Features like "animate" or "plural" are inherent properties of an item in memory, but "subject of the same clause" is not. \textbf{I imagine that what the authors have in mind is that comprehenders assign a clause index to each individual piece of structure as they parse a sentence. Then, when they encounter a verb, they could identify the current clause index, e.g., "3", and then embed that in a retrieval cue, e.g., "subject of clause 3". This is a fine way to introduce a limited amount of relational information into a structural encoding. But note that it means that a good deal of work is now done by the mechanism that continually tracks clause indices and keeps track of the index of the current clause. So, it amounts to a mechanism that does more than simply elaborate the choice of retrieval cues at the verb.}''
\end{quote}

\subsubsection*{Response to R3.2}
\textcolor{red}{??}

\subsection*{Comment R3.3}
\begin{quote}
``\textbf{I also have some questions or reservations about the account of semantic interference effects in terms of features like [+animate]. This is a straightforward enough feature to invoke, and it is a plausible content feature for noun phrases. But I am less sure how well it generalizes. There are many situations in which verb-noun combinations are intuitively a good fit, but where it is less easily cast in terms of features and retrieval cues. For example, we share the intuition that "the teacher drove …" is a better combination than "the little boy drove …", because teachers are plausible drivers, whereas small children are not. This is less easily captured in terms of features and retrieval cues. Maybe the verb "drive" wants a subject with a [+driver] feature. But is this plausibly something that is part of the memory encoding of "teacher" but not "little boy"? Does this require something more than a toy theory of semantic encoding? Or does it predict that only simple features like [+animate] are able to cause semantic interference?}''
\end{quote}


\subsubsection*{Response to R3.3}
It has been shown in the literature that fine-grained semantic features, such as [+fixable] \citep{vandyke_mcelree06} and [+shatterable] \citep{cunnings_sturt_2018retrieval}, are used during cue-based retrieval. The materials in the design employed here were constructed so that the potentially fine-grained features relevant for the situation at hand (e.g., [+can drive], [+can drink] or [+can smile]) could be summed under the umbrella feature [+animate] or actually [+human]. To resolve the critical dependency it was always sufficient to use the umbrella feature [+animate] (or [+human]). The subject and the animate distractor always shared the [+animate] (or more precisely [+human]) feature, while the inanimate distractor was always [-animate] and hence [-human]. There were no animate distractors which mismatched a fine-grained verb-specific retrieval cue like [+can drive]. The results of the plausibility norming, see Figure \ref{fig:plausibility_rating} on page \pageref{fig:plausibility_rating} of the manuscript illustrate that whatever semantic feature determines a good fit between subject and verb matched with the features of the subject and the animate distractor, but not with the features of the inanimate distractor. 

As the reviewer suggested it seems unlikely that all potential fine-grained features are part of an initial memory encoding of each word during sentence processing. But there needs to be a way to retrospectively enrich that memory encoding as the sentence unfolds. There might be a hierarchy of semantic features. A feature like [+can smile] might be a daughter of the feature [+animate/+human]. The degree to which that tree of semantic features becomes activated during sentence processing might differ between individuals. The present study can not provide insight into the specifics of memory encoding. 

We have added the following text to the description of the materials on page \pageref{semantic_features_encoding} of the manuscript:

\Paste{semantic_features_encoding}    

\subsection*{Comment R3.4}
\begin{quote}
``\textbf{The authors offer only limited discussion of why their results differed from those of other studies. To some degree, the paper seems to take the position that since the current studies had huge numbers of participants and hence high statistical power, this study reveals the true state of the world, and other studies should be taken less seriously because their results were less reliable.}''
\end{quote}

\subsubsection*{Response to R3.4}
We think that we have addressed the concerns regarding high- vs.\ lower-powered studies in our Response to R1.5. 

We have created a new subsection in our General Discussion providing an extended discussion of the potential reasons for the differences between our and previous results. We provide the relevant new text passages in our responses below (Response to R3.7 and R3.8).

\subsection*{Comment R3.5}
\begin{quote}
``This may be an over-simplistic approach to the findings. First, \textbf{could there have been an impact of the fact that the study included an unusually large number of experimental items with identical structures, leading to practice effects?}''
\end{quote}

\subsubsection*{Response to R3.5}
To account for practice effects, we have added the centered trial id as a fixed effect as well as by-participant and by-item random slopes to the models analyzing the SPR data. The result pattern did not change (no syntactic interference or interaction, but a semantic interference effect).

\subsection*{Comment R3.6}
\begin{quote}
``\textbf{(One thing that was less clear from the manuscript was the nature and number of any filler items. This receives little discussion in the paper.)}''
\end{quote}


\subsubsection*{Response to R3.6}
We have added the following regarding the filler items to the Procedure section of Experiment 1, page \pageref{fillers1}:

\Paste{fillers1}

\noindent We have also added a brief statement on fillers to the Procedure section of Experiment 2 (page \pageref{fillers2}) and corrected a typo regarding the number of trials per experimental block:

\Paste{fillers2}    

\subsection*{Comment R3.7}
\begin{quote}
``\textbf{Second, could there have been a contribution from the fact that the correct subject NP appeared in a very prominent position, delimited by commas and appearing at a line break?}''
\end{quote}

\subsubsection*{Response to R3.7}
We have added the following text addressing the concern regarding the commas to page \pageref{comma} of the manuscript:

\Paste{comma}

\noindent Regarding the line break, we have added the following text to page \pageref{linebreak}:

\Paste{linebreak}


\subsection*{Comment R3.8}
\begin{quote}
``\textbf{Third, in looking through the full set of experimental items, it appears that the inappropriate subject NP is always the subject of an Aux + Adj predicate, rather than, say, the agent of an action verb. Could this different status of that subject have contributed to the lack of a syntactic interference effect?}

Summarizing, I am overall enthusiastic about this study. But I am less sure of how we should generalize from this specific finding using one specific manipulation. There are multiple possible ways of capturing the lack of a syntactic interference effect, and there could be multiple reasons why the current study might have found different results than other similar studies in the literature.''
\end{quote}

\subsubsection*{Response to R3.8}
We used the same design as \textcite{vandyke07} and \textcite{mertzen}. We manipulated syntactic interference in the same way as they did. Nevertheless, their data showed syntactic interference and our data do not. We have extended the discussion of the potential reasons for the differences in results in the manuscript (cross-linguistic differences, different methods, differences in the items, statistical power, inter-individual differences, see below).  it is unclear why the results differ between the studies. 

However, \textcite{mertzen} added an additional distractor to the items which is relevant regarding the subject status of the distractor(s). We had previously not described this in our manuscript, in the revision we have added the following paragraph to page \pageref{items_mertzen}:

\setcounter{exx}{4}
\Paste{items_mertzen}



\end{document}  